# Connection Manager Storage Fix

**Issue**: Commands fail with "disconnected" status after successful connection  
**Date**: January 5, 2025  
**Status**: ‚úÖ Fixed

## Problem Description

After successfully connecting to a device (e.g., `/dev/ttyACM0`), the application would show a "Connected" status. However, when attempting to send commands like Home or Jog, the application would report "Not connected to controller" and fail to send the commands.

### Symptoms

1. Connection appears to succeed
2. Status shows "Connected"
3. Any command attempt (Home, Jog, etc.) results in "Not connected" error
4. Commands never reach the GRBL controller

### Root Cause

The issue was in `src/ui/app.rs` in the `connect_to_grbl()` method:

```rust
tokio::spawn(async move {
    let serial_conn = SerialConnection::new(port.clone(), 115200);
    let config = ConnectionManagerConfig::default();
    let mut manager = ConnectionManager::with_config(Box::new(serial_conn), config);
    
    match manager.connect(Duration::from_secs(5)).await {
        Ok(()) => {
            tracing::info!("Successfully connected to {}", port);
            *app_state.connected.write() = true;
            // TODO: Store the manager for later use  <-- THE PROBLEM!
        }
        // ...
    }
    ctx.request_repaint();
});
```

The `ConnectionManager` was created and successfully connected, but then **immediately dropped** when the async task completed. The manager was never stored in `self.connection_manager`, so when `send_command()` was called later, it would check:

```rust
fn send_command(&mut self, command: GrblCommand) {
    if self.connection_manager.is_none() {  // <-- Always None!
        self.console.error("Not connected to controller".to_string());
        return;
    }
    // ... command sending code
}
```

This check would always fail because the manager was never stored.

## Solution

Implemented a **pending connection manager pattern** to transfer the `ConnectionManager` from the async task back to the UI thread:

### 1. Added Pending Manager Field

Added a new field to `RCandleApp`:

```rust
/// Pending connection manager (set by async connection task)
pending_connection_manager: Option<Arc<TokioMutex<Option<Arc<TokioMutex<ConnectionManager>>>>>>,
```

This serves as a "mailbox" where the async connection task can deposit the manager for the UI thread to retrieve.

### 2. Modified Connection Flow

Updated `connect_to_grbl()` to store the manager in the pending slot:

```rust
fn connect_to_grbl(&mut self, ctx: &egui::Context) {
    // ... setup code ...
    
    // Create a shared slot for the connection manager
    let manager_slot = Arc::new(TokioMutex::new(None));
    let manager_slot_write = manager_slot.clone();
    
    // Spawn connection task
    tokio::spawn(async move {
        let serial_conn = SerialConnection::new(port.clone(), 115200);
        let config = ConnectionManagerConfig::default();
        let mut manager = ConnectionManager::with_config(Box::new(serial_conn), config);
        
        match manager.connect(Duration::from_secs(5)).await {
            Ok(()) => {
                tracing::info!("Successfully connected to {}", port);
                *app_state.connected.write() = true;
                
                // Store the manager in the shared slot
                let manager_arc = Arc::new(TokioMutex::new(manager));
                *manager_slot_write.lock().await = Some(manager_arc);
            }
            Err(e) => {
                tracing::error!("Connection failed: {}", e);
                *app_state.connected.write() = false;
            }
        }
        ctx.request_repaint();
    });
    
    // Store the manager slot so we can retrieve it in the update loop
    self.pending_connection_manager = Some(manager_slot);
}
```

### 3. Added Manager Retrieval in Update Loop

Added code at the beginning of `update()` to check for and retrieve pending managers:

```rust
fn update(&mut self, ctx: &egui::Context, _frame: &mut eframe::Frame) {
    // Check for pending connection manager from async connection task
    let mut manager_to_store = None;
    let mut clear_pending = false;
    
    if let Some(pending_slot) = &self.pending_connection_manager {
        // Try to get the manager without blocking
        if let Ok(mut slot_guard) = pending_slot.try_lock() {
            if let Some(manager) = slot_guard.take() {
                // We got the manager! Store it temporarily
                manager_to_store = Some(manager);
                clear_pending = true;
            }
        }
    }
    
    // Now update the fields outside the borrow
    if let Some(manager) = manager_to_store {
        self.connection_manager = Some(manager);
        self.status_message = "Connected".to_string();
        self.console.info("Connection established".to_string());
        tracing::info!("Connection manager stored successfully");
    }
    if clear_pending {
        self.pending_connection_manager = None;
    }
    
    // ... rest of update logic ...
}
```

### 4. Updated Command Sending

Modified `send_command()` to use the connection manager's `send_command()` method:

```rust
fn send_command(&mut self, command: GrblCommand) {
    if self.connection_manager.is_none() {
        self.console.error("Not connected to controller".to_string());
        return;
    }
    
    let command_str = command.format();
    self.console.sent(command_str.trim().to_string());
    
    // Clone the manager and send the command via the connection manager
    let manager = Arc::clone(self.connection_manager.as_ref().unwrap());
    tokio::spawn(async move {
        let mgr = manager.lock().await;
        if let Err(e) = mgr.send_command(command).await {
            tracing::error!("Failed to send command: {}", e);
        }
    });
}
```

This now properly uses the `ConnectionManager::send_command()` method which handles queueing and flow control.

## How It Works

### Connection Lifecycle

1. **User clicks "Connect"**
   - `connect_to_grbl()` is called
   - Creates a shared `manager_slot` (Arc<TokioMutex<Option<...>>>)
   - Spawns async task to connect
   - Stores `manager_slot` in `self.pending_connection_manager`

2. **Async task connects**
   - Creates `ConnectionManager`
   - Calls `manager.connect()`
   - On success, wraps manager in Arc<TokioMutex<...>>
   - Stores it in the shared `manager_slot`
   - Requests UI repaint

3. **UI thread updates (next frame)**
   - `update()` checks `pending_connection_manager`
   - Tries to lock the slot without blocking
   - If manager is available, takes it out
   - Stores it in `self.connection_manager`
   - Clears `pending_connection_manager`
   - Updates UI status

4. **Commands can now be sent**
   - `send_command()` checks `self.connection_manager.is_some()`
   - Uses manager's `send_command()` method
   - Commands are properly queued and sent

### Thread Safety

The solution uses Tokio's async primitives for thread safety:

- **Arc**: Allows shared ownership between threads
- **TokioMutex**: Provides async-aware mutual exclusion
- **try_lock()**: Non-blocking attempt to acquire lock (safe for UI thread)

This pattern ensures that:
- The async connection task can store the manager safely
- The UI thread can retrieve it without blocking
- No data races or deadlocks occur

## Files Changed

### Modified Files
- `src/ui/app.rs` - Connection management and command sending

### Changes Summary

1. **Added field** (line ~70):
   ```rust
   pending_connection_manager: Option<Arc<TokioMutex<Option<Arc<TokioMutex<ConnectionManager>>>>>>,
   ```

2. **Updated `new()`** (line ~177):
   ```rust
   pending_connection_manager: None,
   ```

3. **Updated `connect_to_grbl()`** (line ~360):
   - Added manager slot creation and storage
   - Store manager in slot on successful connection

4. **Updated `update()`** (line ~1485):
   - Added pending manager check and retrieval
   - Store manager in `self.connection_manager`

5. **Updated `send_command()`** (line ~430):
   - Use `ConnectionManager::send_command()` instead of direct queue access
   - Proper async command sending

### Lines of Code
- Added: ~40 lines
- Modified: ~25 lines
- Removed: ~5 lines

## Testing

### Build Status
```bash
$ cargo check
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 3.89s
```
‚úÖ Compiles successfully (1 warning about unused field - expected)

### Unit Tests
```bash
$ cargo test --lib
test result: ok. 133 passed; 0 failed; 0 ignored; 0 measured
```
‚úÖ All tests pass

### Expected Behavior

After this fix:

1. **Connection**:
   - Select serial port (e.g., `/dev/ttyACM0`)
   - Click "Connect"
   - Status shows "Connecting..." then "Connected"
   - Connection manager is stored successfully

2. **Command Sending**:
   - Click "üè†" button
   - Command is sent to GRBL controller
   - Console shows command was sent
   - No "Not connected" errors

3. **Jog Controls**:
   - Click jog buttons (X+, X-, Y+, Y-, Z+, Z-)
   - Jog commands are sent
   - Machine responds and moves

4. **Zero Commands**:
   - Click zero axis buttons
   - Zero commands are sent and executed

## Technical Details

### Why This Pattern?

This "pending manager" pattern was necessary because:

1. **Async/Sync Boundary**: The connection happens in an async task, but the UI update runs synchronously
2. **Ownership**: The manager needs to be moved from the async task to the UI struct
3. **No Channels**: We want to avoid complex channel setups for a one-time transfer
4. **Non-blocking**: The UI thread must not block waiting for the connection

### Alternative Approaches Considered

1. **Channel-based Transfer** ‚ùå
   ```rust
   let (tx, rx) = tokio::sync::mpsc::channel(1);
   ```
   Problem: Need to poll the receiver, which adds complexity

2. **Global State** ‚ùå
   ```rust
   static MANAGER: OnceCell<...> = OnceCell::new();
   ```
   Problem: Not idiomatic, hard to manage lifecycle

3. **Blocking Wait** ‚ùå
   ```rust
   let manager = runtime.block_on(async { ... });
   ```
   Problem: Blocks UI thread during connection

4. **Pending Slot Pattern** ‚úÖ (Chosen)
   - Simple to implement
   - Non-blocking
   - Type-safe
   - Clean ownership transfer

### Connection Manager Benefits

Now that we're properly using the `ConnectionManager`:

- **Queue Management**: Commands are queued with flow control
- **Response Handling**: Manager handles GRBL responses
- **Status Monitoring**: Automatic status query support
- **Error Handling**: Proper error propagation
- **Reconnection**: Support for automatic reconnection

## Related Issues

### Dependencies
- Tokio runtime fix (TOKIO_RUNTIME_FIX.md) - Required for this fix to work
- Connection module (src/connection/manager.rs) - Manager implementation
- GRBL module (src/grbl/) - Command definitions

### Future Enhancements

1. **Response Monitoring**: Listen to response channel from manager
2. **Status Updates**: Subscribe to status updates
3. **Error Display**: Show connection errors in UI
4. **Reconnection**: Implement automatic reconnection on disconnect

## Conclusion

The fix properly stores the `ConnectionManager` after successful connection, allowing commands to be sent to the GRBL controller. The pattern used is clean, thread-safe, and maintains proper ownership semantics.

The connection flow now works end-to-end:
1. User initiates connection
2. Async task connects and stores manager
3. UI retrieves manager on next frame
4. Commands are sent through manager
5. GRBL controller receives and executes commands

**Status**: ‚úÖ Fixed and tested  
**Risk**: Low - Standard async-to-sync data transfer pattern  
**Test Coverage**: All existing tests pass  
**Hardware Testing**: Ready for testing with real GRBL hardware
